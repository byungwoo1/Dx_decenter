# -*- coding: utf-8 -*-
"""dx lens detection

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1o547hKpKFrBtxG5TqrDCzXVCg-_4JNez
"""

!git clone https://github.com/yoonnyi/lenstest.git

# Commented out IPython magic to ensure Python compatibility.
# %cd lenstest
!unzip -oq 1207_train1.zip

# Commented out IPython magic to ensure Python compatibility.
# %cd lenstest
!unzip -oq 1207_train2.zip

# Commented out IPython magic to ensure Python compatibility.
# %cd lenstest
!unzip -oq 1207_valid.zip

# Commented out IPython magic to ensure Python compatibility.
# %cd lenstest
!unzip -oq 1207_test.zip

# Commented out IPython magic to ensure Python compatibility.
# %cd /content
!git clone https://github.com/ultralytics/yolov5.git

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/yolov5/
!pip install -r requirements.txt

!pwd

# Commented out IPython magic to ensure Python compatibility.
# %cat /content/lenstest/data.yaml

# Commented out IPython magic to ensure Python compatibility.
# %cd /
from glob import glob
train_img_list = glob('/content/lenstest/train/images/*.jpg')
val_img_list = glob('/content/lenstest/valid/images/*.jpg')
print(len(train_img_list)), print(len(val_img_list))

train_img_list[:3]

with open('/content/lenstest/train.txt', 'w') as f:
  f.write('\n'.join(train_img_list) + '\n')

with open('/content/lenstest/val.txt', 'w') as f:
  f.write('\n'.join(val_img_list) + '\n')

!head -5 /content/lenstest/train.txt

import yaml

with open('/content/lenstest/data.yaml', 'r') as f:
  data = yaml.safe_load(f)

print(data)

data['train'] = '/content/lenstest/train.txt'
data['val'] = '/content/lenstest/val.txt'

with open('/content/lenstest/data.yaml', 'w') as f:   ## 데이타에 대한 설정 yaml 파일
  yaml.dump(data, f)

print(data)

# Commented out IPython magic to ensure Python compatibility.
# %cat /content/lenstest/data.yaml

!cat /content/yolov5/models/yolov5m.yaml ## 모델에 대한 설정 yaml 파일

# Commented out IPython magic to ensure Python compatibility.
## train 재학습 시키는 것
# %cd /content/yolov5/  

!python train.py --img 864 --batch 32 --epochs 40 --data /content/lenstest/data.yaml --cfg ./models/yolov5s.yaml --weights yolov5s.pt --name lenstrain_results



from IPython.display import Image
import os

val_img_path = val_img_list[3]
val_img_path

!python detect.py --weights /content/yolov5/runs/train/lenstrain_results/weights/best.pt --img 864 --conf 0.7 --save-txt --save-crop --save-conf --source /content/lenstest/valid/images

!python detect.py --weights /content/drive/MyDrive/best.pt --img 864 --conf 0.7 --save-txt --save-crop --save-conf --source /content/lenstest/valid/images

!python detect.py --weights /content/drive/MyDrive/best2.pt --img 864 --conf 0.7 --save-txt --save-crop --save-conf --source /content/lenstest/valid/images

val_img_list[:5]

val_img_path = val_img_list[5]
img_file = os.path.join('/content/lenstest/valid/images/', os.path.basename(val_img_path))
Image(img_file)

img_file

output = '/content/yolov5/runs/detect/exp/300125.jpg'
Image(output)

!python detect.py --weights /content/yolov5/runs/train/lenstrain_results/weights/best.pt --img 864 --conf 0.7 --save-txt --save-crop --save-conf --source /content/lenstest/test/images

!python detect.py --weights /content/yolov5/runs/train/lenstrain_results/weights/best.pt --img 864 --conf 0.6 --save-txt --save-crop --save-conf --source /content/lenstest/test/images

!python detect.py --weights /content/drive/MyDrive/best.pt --img 864 --conf 0.6 --save-txt --save-crop --save-conf --source /content/lenstest/test/images

!python detect.py --weights /content/drive/MyDrive/best2.pt --img 864 --conf 0.7 --save-txt --save-crop --save-conf --source /content/lenstest/test/images

output = '/content/yolov5/runs/detect/finaltest/30070(NG).jpg'
Image(output)

"""# 성능 비교하기"""

# scores_raw = np.random.randint(30,99,10)

## 스코어 raw를 거리 계산 식으로 만들기
# dist_real = 
# df = pd.DataFrame({"거리":dist_real})
# df.index.name='ID'
# df.T

## 거리 기준 점수(threshold)를 0.05이라고 가정한다

# threshold =  0.05
# # 거리 초과 ng (positive)를 0으로 인코딩했다 (~ 사용함, 0.05보다 아래면 , ok가 1, ng가 0)
# pred_dist = ~(df["거리"] > threshold)
# df["예측"] = pred_dist.astype(int)

# 거리 ok ng를 리스트 생성 (거리 0.05 초과하면 0) 리스트 만들어주기
# df['실제'] = np.array([0,0,1,0,1,0,1,0,1,1~~~~])
# df.T

## 혼돈 매트릭스와 분류 평가 점수 보기

# def show_clf_result(y_test, y_pred):
#    print(confusion_matrix(y_test, y_pred))
#    print(classification_report(y_test, y_pred))

# y_pred = df['예측'].values
# y_test = df['실제'].values
# score_sorted = df['거리'].values

# show_clf_result(y_test, y_pred)



import os
path = "/content/yolov5/runs/detect/finaltest/labels"
file = os.listdir(path)

print(file)

f = open("/content/yolov5/runs/detect/finaltest/labels/30070(NG).txt", "r")
line1= f.readlines()
line1[0]

line1[0].split()

import numpy as np
import pandas as pd

line1_0num = list(map(float, line1[0].split()))
print(line1_0num)
print(line1_0num[1])

line1_1num = list(map(float, line1[1].split()))
print(line1_1num)
print(line1_1num[1])

# 2번째가 x, 3번째가 y  // 나중에 거리값 곱해줘야함

dist_scale = (((line1_0num[1]- line1_1num[1])**2) + (((line1_0num[2]- line1_1num[2]))**2))**(1/2)
dist_scale

file.sort()

file
files = file

files



dist = []

import numpy as np
import pandas as pd

for file in files :
  f = open(f"/content/yolov5/runs/detect/finaltest/labels/{file}", "r")
  line1= f.readlines()
  line1[0]
  line1_0num = list(map(float, line1[0].split()))
  line1_1num = list(map(float, line1[1].split()))
  dist_real = (((line1_0num[1]- line1_1num[1])**2) + ((line1_0num[2]- line1_1num[2])**2))**(1/2)*7.25
  dist.append(dist_real)

dist = np.round(dist, 3)
dist

df = pd.DataFrame({"거리":dist})
df.index.name='ID'
df.T

## 거리 기준 점수(threshold)를 0.05이라고 가정한다

threshold =  0.05

# # 거리 초과 ng (positive)를 0으로 인코딩했다 (~ 사용함, 0.05보다 아래면 , ok가 1, ng가 0)

pred_dist = ~(df["거리"] > threshold)
df["예측"] = pred_dist.astype(int)

# 거리 ok ng를 리스트 생성 (거리 0.05 초과하면 0) 리스트 만들어주기
df['실제'] = np.array([0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,1,0,1,1,1,1,1,1,0,0,1,0,1])
df.T

## 혼돈 매트릭스와 분류 평가 점수 보기

import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc
from sklearn.metrics import precision_score, recall_score
from sklearn.metrics import precision_recall_curve
from sklearn.linear_model import SGDClassifier
from sklearn.preprocessing import StandardScaler

def show_clf_result(y_test, y_pred):
   print(confusion_matrix(y_test, y_pred))
   print(classification_report(y_test, y_pred))

y_pred = df['예측'].values
y_test = df['실제'].values
score_sorted = df['거리'].values

show_clf_result(y_test, y_pred)

df

output = '/content/yolov5/runs/detect/finaltest/30080(OK).jpg'
Image(output)



"""# 실제 거리 계수 평균으로"""

dist2 = []

import numpy as np
import pandas as pd

for file in files :
  f = open(f"/content/yolov5/runs/detect/finaltest/labels/{file}", "r")
  line1= f.readlines()
  line1[0]
  line1_0num = list(map(float, line1[0].split()))
  line1_1num = list(map(float, line1[1].split()))
  dist2_real = (((line1_0num[1]- line1_1num[1])**2) + ((line1_0num[2]- line1_1num[2])**2))**(1/2)*6.76
  dist2.append(dist2_real)

dist2 = np.round(dist2, 5)
dist2

df2 = pd.DataFrame({"거리":dist2})
df2.index.name='ID'
df2.T

## 거리 기준 점수(threshold)를 0.05이라고 가정한다

threshold =  0.05

# # 거리 초과 ng (positive)를 0으로 인코딩했다 (~ 사용함, 0.05보다 아래면 , ok가 1, ng가 0)

pred_dist2 = ~(df2["거리"] > threshold)
df2["예측"] = pred_dist2.astype(int)

# 거리 ok ng를 리스트 생성 (거리 0.05 초과하면 0) 리스트 만들어주기
df2['실제'] = np.array([0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,1,0,1,1,1,1,1,1,0,0,1,0,1])
df2.T

## 혼돈 매트릭스와 분류 평가 점수 보기

import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc
from sklearn.metrics import precision_score, recall_score
from sklearn.metrics import precision_recall_curve
from sklearn.linear_model import SGDClassifier
from sklearn.preprocessing import StandardScaler

def show_clf_result(y_test2, y_pred2):
   print(confusion_matrix(y_test2, y_pred2))
   print(classification_report(y_test2, y_pred2))

y_pred2 = df2['예측'].values
y_test2 = df2['실제'].values
score_sorted2 = df2['거리'].values

show_clf_result(y_test2, y_pred2)

df2

output = '/content/yolov5/runs/detect/finaltest/30091(OK).jpg'
Image(output)



"""# yolov5l 로 적용"""

!cat /content/yolov5/models/yolov5l.yaml ## 모델에 대한 설정 yaml 파일

# Commented out IPython magic to ensure Python compatibility.
## train 재학습 시키는 것
# %cd /content/yolov5/  

!python train.py --img 864 --batch 12 --epochs 35 --data /content/lenstest/data.yaml --cfg ./models/yolov5l.yaml --weights yolov5l.pt --name lenstrain_results

!python detect.py --weights /content/drive/MyDrive/best3.pt --img 864 --conf 0.7 --save-txt --save-crop --save-conf --source /content/lenstest/test/images

dist3 = []

import numpy as np
import pandas as pd

for file in files :
  f = open(f"/content/yolov5/runs/detect/final2/labels/{file}", "r")
  line1= f.readlines()
  line1[0]
  line1_0num = list(map(float, line1[0].split()))
  line1_1num = list(map(float, line1[1].split()))
  dist3_real = (((line1_0num[1]- line1_1num[1])**2) + ((line1_0num[2]- line1_1num[2])**2))**(1/2)*7.25
  dist3.append(dist3_real)

dist3 = np.round(dist3, 5)
dist3

df3 = pd.DataFrame({"거리":dist3})
df3.index.name='ID'
df3.T

## 거리 기준 점수(threshold)를 0.05이라고 가정한다

threshold =  0.05

# # 거리 초과 ng (positive)를 0으로 인코딩했다 (~ 사용함, 0.05보다 아래면 , ok가 1, ng가 0)

pred_dist3 = ~(df3["거리"] > threshold)
df3["예측"] = pred_dist3.astype(int)

# 거리 ok ng를 리스트 생성 (거리 0.05 초과하면 0) 리스트 만들어주기
df3['실제'] = np.array([0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,1,0,1,1,1,1,1,1,0,0,1,0,1])
df3.T

## 혼돈 매트릭스와 분류 평가 점수 보기

import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc
from sklearn.metrics import precision_score, recall_score
from sklearn.metrics import precision_recall_curve
from sklearn.linear_model import SGDClassifier
from sklearn.preprocessing import StandardScaler

def show_clf_result(y_test3, y_pred3):
   print(confusion_matrix(y_test3, y_pred3))
   print(classification_report(y_test3, y_pred3))

y_pred3 = df3['예측'].values
y_test3 = df3['실제'].values
score_sorted3 = df3['거리'].values

show_clf_result(y_test3, y_pred3)

df3

"""# 계산식 가로 / 세로 실제 비율 곱해서 다시"""



dist4 = []

import numpy as np
import pandas as pd

for file in files :
  f = open(f"/content/yolov5/runs/detect/finaltest/labels/{file}", "r")
  line1= f.readlines()
  line1[0]
  line1_0num = list(map(float, line1[0].split()))
  line1_1num = list(map(float, line1[1].split()))
  dist4_real = (((7.42*(line1_0num[1]- line1_1num[1]))**2) + ((5.6*(line1_0num[2]- line1_1num[2]))**2))**(1/2)
  dist4.append(dist4_real)

dist4 = np.round(dist4, 5)
dist4

df4 = pd.DataFrame({"거리":dist4})
df4.index.name='ID'
df4.T

## 거리 기준 점수(threshold)를 0.05이라고 가정한다

threshold =  0.05

# # 거리 초과 ng (positive)를 0으로 인코딩했다 (~ 사용함, 0.05보다 아래면 , ok가 1, ng가 0)

pred_dist4 = ~(df4["거리"] > threshold)
df4["예측"] = pred_dist4.astype(int)

# 거리 ok ng를 리스트 생성 (거리 0.05 초과하면 0) 리스트 만들어주기
df4['실제'] = np.array([0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,1,0,1,1,1,1,1,1,0,0,1,0,1])
df4.T

## 혼돈 매트릭스와 분류 평가 점수 보기

import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc
from sklearn.metrics import precision_score, recall_score
from sklearn.metrics import precision_recall_curve
from sklearn.linear_model import SGDClassifier
from sklearn.preprocessing import StandardScaler

def show_clf_result(y_test4, y_pred4):
   print(confusion_matrix(y_test2, y_pred4))
   print(classification_report(y_test2, y_pred4))

y_pred4 = df4['예측'].values
y_test4 = df4['실제'].values
score_sorted4 = df4['거리'].values

show_clf_result(y_test4, y_pred4)

df4

output = '/content/yolov5/runs/detect/finaltest/30089(OK).jpg'
Image(output)

